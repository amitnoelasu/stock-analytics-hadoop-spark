# ðŸ“ˆ Stock Market ETL Pipeline (PySpark + Docker)

A modular, production-style **PySpark ETL pipeline** that ingests raw stock price data (CSV), enriches it with metadata, computes technical indicators (moving averages, volatility, returns), and writes the results as **partitioned Parquet datasets**.

The project is fully containerized using Docker and includes optional integration with **HDFS and Hive** for distributed storage/queries.

# Data source: https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset?resource=download

---

## ðŸš€ Features

### âœ” Extract
- Automatically loads all ticker CSV files  
- Parses dates, normalizes schema  
- Loads NASDAQ metadata  

### âœ” Transform
- Computes:
  - Daily returns  
  - Rolling volatility (20-day)  
  - Moving averages (MA20, MA50)  
- Joins prices with metadata  
- Cleans up column types  

### âœ” Load
- Writes cleaned, enriched datasets as **partitioned Parquet**  
- Supports:
  - Local filesystem  
  - **HDFS** (`hdfs://â€¦`)  
  - Optional Hive table creation  

### âœ” Built-in SQL Queries
After ETL, Spark runs demonstration SQL queries for exploration.

---

## ðŸ“‚ Project Structure

etl/
â”‚
â”œâ”€â”€ extract/
â”‚   â”œâ”€â”€ prices_loader.py
â”‚   â””â”€â”€ metadata_loader.py
â”‚
â”œâ”€â”€ transform/
â”‚   â”œâ”€â”€ indicators.py       # returns, MA20, MA50, volatility
â”‚   â”œâ”€â”€ joiner.py           # join w/ metadata
â”‚   â””â”€â”€ enrich.py           # orchestrates transformations
â”‚
â”œâ”€â”€ load/
â”‚   â””â”€â”€ writer.py           # writes Parquet (local or HDFS)
â”‚
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ sql_examples.py     # exploratory SQL queries
â”‚
â”œâ”€â”€ spark_app.py            # SparkSession builder
â”œâ”€â”€ config.py               # CLI + runtime config
â””â”€â”€ pipeline.py             # Full ETL pipeline orchestration

run_etl.py                  # Entrypoint
Dockerfile
docker-compose.yml



# Input data format
Date,Open,High,Low,Close,Adj Close,Volume
2024-01-02,189.98,190.85,187.20,189.00,189.00,45000000

# Metadata CSV example
Symbol,Security Name,Listing Exchange,Market Category,ETF,...
AAPL,Apple Inc,Nasdaq Global Select,Q,...

# Output format (Parquet)
prices_enriched/
â””â”€â”€ symbol=AAPL/
      part-xxxxx.snappy.parquet
â””â”€â”€ symbol=AMZN/
â””â”€â”€ symbol=MSFT/

# Output path for test-data: /test_data/clean


